{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nisinghal/AirlineDatabase/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq7sIzVyAZsX",
        "colab_type": "code",
        "outputId": "2e0b3d31-1fa9-4811-fa81-4b2044dd9f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "import nltk, string, random\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1319,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex3YP_-aAl0Z",
        "colab_type": "code",
        "outputId": "f9886d50-da43-4d49-a6df-e2ad3e048591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFcpp4HpAnWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafake = pd.read_csv(\"/content/drive/My Drive/data/politifact_fake - politifact_fake.csv\")\n",
        "datareal = pd.read_csv(\"/content/drive/My Drive/data/politifact_real - politifact_real.csv\")\n",
        "datafake.drop(columns=['id','news_url'],inplace=True)\n",
        "datareal.drop(columns=['id','news_url'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isW4UDBPT9cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ps = PorterStemmer()\n",
        "lem = WordNetLemmatizer()\n",
        "stopword = set(stopwords.words( 'english' ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWeXr2BvEakM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(data):\n",
        "  return re.sub(r'[^(a-zA-Z)\\s]','', data)\n",
        "def remstop(data):\n",
        "  global stopword\n",
        "  return [w for w in data if w not in stopword]\n",
        "def tagpos(data):\n",
        "  return nltk.pos_tag(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1klAvhkqP6Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents=[]\n",
        "\n",
        "def addindocs(data,flag):\n",
        "  global documents\n",
        "  for p in data.title:\n",
        "    documents.append(((clean(p).lower()),flag))\n",
        "\n",
        "addindocs(datareal, \"true\")\n",
        "addindocs(datafake,\"false\")\n",
        "random.shuffle(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R2BPgZ1Ap9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words=[]\n",
        "allowedpos=[\"IN\",\"NN\" ,\"NNP\",\"PRP\",\"PRP$\" , \"RP\",\"VBP\"]\n",
        "\n",
        "def addinwords(data):\n",
        "  global allowedpos, words\n",
        "  for p in data.title:\n",
        "    tokenized = word_tokenize(clean(p))\n",
        "    stopremoved=remstop(tokenized)\n",
        "    postagged = nltk.pos_tag(tokenized)\n",
        "    for w in postagged:\n",
        "      if w[1] in allowedpos:\n",
        "        words.append(lem.lemmatize(w[0].lower()))\n",
        "\n",
        "addinwords(data_real)\n",
        "addinwords(data_fake)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiLJK3hVA1XM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = nltk.FreqDist(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulacRWspA2eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordfeatures=[]\n",
        "for word in words:\n",
        "  if(words[word]>2):\n",
        "    wordfeatures.append(word)\n",
        "\n",
        "def docfeatures(doc):\n",
        "    docwords = word_tokenize(doc)\n",
        "    # for i,word in enum?(word)\n",
        "    features = {}\n",
        "    for word in wordfeatures:\n",
        "        features[word] = (lem.lemmatize(word) in docwords)\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hu5E2oWA4uT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresets = [(docfeatures(d), c) for (d,c) in documents]\n",
        "trainset, testset = featuresets[:800], featuresets[800:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uBZ1G_NA6hY",
        "colab_type": "code",
        "outputId": "60ac7fc4-f33f-4a3c-93f9-6dca977924ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(trainset)\n",
        "print(nltk.classify.accuracy(classifier, testset)*100)"
      ],
      "execution_count": 1316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "92.98245614035088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqHSahariuau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "0f9bee39-2520-4b4a-ac9f-f7725b1796b1"
      },
      "source": [
        "classifier.show_most_informative_features(20)"
      ],
      "execution_count": 1317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "              transcript = True             true : false  =     20.7 : 1.0\n",
            "                   after = True            false : true   =     16.0 : 1.0\n",
            "                    that = True            false : true   =     10.1 : 1.0\n",
            "                    week = True             true : false  =      9.9 : 1.0\n",
            "                    will = True            false : true   =      8.8 : 1.0\n",
            "            presidential = True             true : false  =      8.5 : 1.0\n",
            "                 million = True            false : true   =      8.2 : 1.0\n",
            "                  before = True            false : true   =      8.2 : 1.0\n",
            "                    care = True             true : false  =      7.8 : 1.0\n",
            "                  health = True             true : false  =      7.8 : 1.0\n",
            "                      if = True            false : true   =      7.5 : 1.0\n",
            "                     you = True            false : true   =      7.3 : 1.0\n",
            "                      is = True            false : true   =      7.2 : 1.0\n",
            "                     out = True            false : true   =      6.9 : 1.0\n",
            "                     are = True            false : true   =      6.5 : 1.0\n",
            "                 senator = True             true : false  =      6.5 : 1.0\n",
            "                congress = True             true : false  =      5.8 : 1.0\n",
            "                     all = True            false : true   =      5.6 : 1.0\n",
            "                     our = True            false : true   =      5.6 : 1.0\n",
            "                      be = True            false : true   =      5.5 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJbGHv6cjitx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "currclassifier = open( \"naivebayes.pickle\" , \"wb\" )\n",
        "pickle.dump (classifier, currclassifier)\n",
        "currclassifier.close ()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THGjutWBms59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}